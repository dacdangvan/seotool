services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-seo-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ai_seo_tool
      # Allow connections from any host (for local development)
      POSTGRES_HOST_AUTH_METHOD: md5
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/migrations:/docker-entrypoint-initdb.d/01-migrations
      - ./database/seeds:/docker-entrypoint-initdb.d/02-seeds
    command: ["postgres", "-c", "listen_addresses=*"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for BullMQ and Cache
  redis:
    image: redis:7-alpine
    container_name: ai-seo-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend Orchestrator
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-seo-backend
    restart: unless-stopped
    environment:
      NODE_ENV: production
      PORT: 3000
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ai_seo_tool
      DB_USER: postgres
      DB_PASSWORD: postgres
      REDIS_URL: redis://redis:6379
      REDIS_HOST: redis
      REDIS_PORT: 6379
      LOG_LEVEL: info
      CORS_ORIGIN: http://localhost:3001
    ports:
      - "3000:3000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # Standalone Crawler Worker (Section 18)
  # Runs independently, continuously polling for crawl jobs
  crawler-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-seo-crawler-worker
    restart: unless-stopped
    command: ["node", "dist/crawler/standalone_worker.js"]
    environment:
      NODE_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ai_seo_tool
      DB_USER: postgres
      DB_PASSWORD: postgres
      REDIS_URL: redis://redis:6379
      REDIS_HOST: redis
      REDIS_PORT: 6379
      # Crawler-specific config
      CRAWLER_POLL_INTERVAL: "10000"
      CRAWLER_MAX_CONCURRENT: "2"
      CRAWLER_ENABLE_SCHEDULING: "true"
      CRAWLER_SHUTDOWN_TIMEOUT: "30000"
      LOG_LEVEL: info
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_started

volumes:
  postgres_data:
  redis_data:
